from collections import OrderedDict
import json
from multiprocessing import cpu_count
from pathlib import Path
import pickle
from textwrap import wrap

import feather
import lightgbm as lgb
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from prettytable import PrettyTable
from pandas_summary import DataFrameSummary
from IPython.display import display
from sklearn.base import TransformerMixin
from sklearn.externals.joblib import Parallel, delayed, parallel_backend
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.preprocessing import OrdinalEncoder
from sklearn.model_selection import train_test_split
from sklearn_pandas import CategoricalImputer
try:
    from sklearn.impute import SimpleImputer
except ImportError:
    # scikit-learn <= 0.19
    from sklearn.preprocessing import Imputer as SimpleImputer

from basedir import TRAIN, TEST
from utils import create_or_load


seed = 1
np.random.seed(seed)


def main():
    data, summary = create_or_load(TRAIN)

    id_column = 'MachineIdentifier'
    target_column = 'HasDetections'
    num_columns = [
        'Census_TotalPhysicalRAM',
        'Census_InternalPrimaryDiagonalDisplaySizeInInches',
        'Census_InternalBatteryNumberOfCharges']
    cat_columns = [col for col in data.columns if col not in num_columns]
    cat_columns.remove(target_column)
    cat_columns.remove(id_column)

    identifier = data[id_column]
    stats = summary.columns_stats.T
    data.drop(columns=id_column, inplace=True)
    subsets = create_train_test(data, target_column)
    results = prepare_parallel(subsets, stats, num_columns, cat_columns)

    # results = prepare_dataset(*subsets, num_columns, cat_columns, summary.columns_stats.T)
    # print(results.keys())


def create_train_test(dataset, target_column, test_size=0.1, seed=seed):
    n = len(dataset)
    train, valid = train_test_split(
        np.arange(n), test_size=test_size, random_state=seed,
        stratify=dataset[target_column])
    X, y = dataset.drop(columns=target_column), dataset[target_column]
    print(f'Train: {len(train)} / Valid: {len(valid)}')
    return X.iloc[train], X.iloc[valid], y.iloc[train], y.iloc[valid]


def prepare_parallel(data: tuple, stats: pd.DataFrame, num_cols: list, cat_cols: list, n_jobs=None):
    n_jobs = n_jobs or cpu_count()
    x_trn, x_val, y_trn, y_val = data
    cols = x_trn.columns.tolist()

    batches = []
    for c in cols:
        if c not in num_cols and c not in cat_cols:
            continue
        cat = c in cat_cols
        batches.append({
            'name': c, 'trn_col': x_trn[c], 'val_col': x_val[c],
            'stats': stats.loc[c], 'categorical': cat})

    with Parallel(n_jobs=n_jobs) as parallel:
        results = parallel(delayed(prepare_single)(**b) for b in batches[:3])

    breakpoint()
    x_trn_enc, x_val_enc = [], []
    transformers = {}
    for name, result in results:
        x_trn_enc.append(result.pop('x_trn'))
        x_val_enc.append(result.pop('x_val'))
        transformers[name] = result

    return results


def prepare_single(name, trn_col, val_col, stats, categorical):
    result = {}
    if not informative(trn_col, stats):
        return name, result

    if categorical:
        x = trn_col
        x = x.astype(str)
        x = x.replace({x: np.nan for x in ('None', 'nan', '', 'n/a', 'NA')})
        most_freq, _ = next(x.value_counts().items())
        x[pd.isnull(x)] = most_freq
        labels = {x: i for i, x in enumerate(x.unique())}
        result['impute'] = most_freq
        result['encode'] = labels
        result['x_trn'] = x.map(labels)

        x = val_col
        x = x.astype(str)
        x = x.replace({x: np.nan for x in ('None', 'nan', '', 'n/a', 'NA')})
        x[pd.isnull(x)] = most_freq
        result['x_val'] = x.map(labels)

    else:
        x = trn_col
        x = x.astype(np.float32)
        mean = x.mean()
        x[pd.isnull(x)] = mean
        result['impute'] = mean
        result['x_trn'] = x

        x = val_col
        x = x.astype(np.float32)
        x[pd.isnull(x)] = mean
        result['x_val'] = x

    return name, result


def prepare_dataset(x_train, x_valid, y_train, y_valid, num_cols, cat_cols, stats):
    columns = x_train.columns.tolist()
    results = {}

    for col in columns:
        x, x_val = x_train[col], x_valid[col]

        if not informative(x, col, stats):
            continue

        if col in cat_cols:
            x = x.astype(str)
            x = x.replace({x: np.nan for x in ('None', 'nan', '', 'n/a', 'NA')})
            most_freq, _ = next(x.value_counts().items())
            x[pd.isnull(x)] = most_freq
            labels = {x: i for i, x in enumerate(x.unique())}
            x = x.map(labels)
            x_val = x_val.astype(str)
            x_val = x_val.replace({x: np.nan for x in ('None', 'nan', '', 'n/a', 'NA')})
            x_val[pd.isnull(x_val)] = most_freq
            x_val = x_val.map(labels)
            results[col] = {'x_trn': x, 'x_val': x_val,
                            'impute': most_freq, 'encode': labels}

        elif col in num_cols:
            x = x.astype(np.float32)
            mean = x.mean()
            x[pd.isnull(x)] = mean
            x_val = x_val.astype(np.float32)
            x_val[pd.isnull(x_val)] = mean
            results[col] = {'x_trn': x, 'x_val': x_val, 'impute': mean}

        else:
            continue

        results[col] = {'y_trn': y_train.astype(np.float32),
                        'y_val': y_valid.astype(np.float32)}

    return results


def informative(x, stats, max_missing=0.8, max_uniq_ratio=0.7, max_value_freq=0.95):
    if max_missing is not None:
        pct = float(stats['missing_perc'].strip('%'))
        if pct >= max_missing:
            return False

    if max_uniq_ratio:
        ratio = stats['uniques']/stats['counts']
        if ratio >= max_uniq_ratio:
            return False

    if max_value_freq:
        freqs = x.dropna().value_counts()/stats['counts']
        for val, freq in freqs.items():
            if freq > max_value_freq:
                return False

    return True



# class Replace:
#
#     __slots__ = ('na_values', 'rep')
#
#     def __init__(self, na_values=('None', 'nan', '', 'n/a', 'NA'), rep=np.nan):
#         self.na_values = na_values
#         self.rep = rep
#
#     def __call__(self, column: pd.Series):
#         return column.replace({x: self.rep for x in self.na_values})
#
#
# class AsType:
#     __slots__ = ('type',)
#
#     def __init__(self, type):
#         self.type = type
#
#     def __call__(self, column: pd.Series):
#         return column.astype(self.type)
#
#
# class Impute:
#
#
# class Encode:
#
#     def __init__(self):
#         self.encoder = {}
#
#     def __call__(self, x: pd.Series):
#         uniq = x.unique()
#         labels = uniq()



if __name__ == '__main__':
    main()
