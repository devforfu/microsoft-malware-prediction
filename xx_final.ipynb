{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Unconciouos Kaggler's Notebook\n",
    "\n",
    "A few simple notes about dataset encoding, feature engineering and ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from itertools import combinations, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import feather\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import hamming\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import auc\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedir import DATA, TRAIN, TEST\n",
    "from info import efficient_types, id_feature, target_feature\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Converting Into Binary Format\n",
    "\n",
    "The original dataset is provided in the CSV format which is very inefficient in the terms of reading/writing speed. Also, this format doesn't allow to store any information about data types. Therefore, to speed up and simplify the data loading process, let's convert the dataset into binary format.\n",
    "\n",
    "Also, it could be convenient to concatenate the training and testing datasets together, and drop the `MachineIdentifier` column. (We can use `pandas.DataFrame` index to uniquely identify the observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def default_saver(df, out, **params):\n",
    "    cols = df.select_dtypes(include=[np.float16]).columns\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    outfile = f'{out}.feather'\n",
    "    df.to_feather(outfile)\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Converter:\n",
    "    \"\"\"Reads dataset in CSV format and converts into binary file.\"\"\"\n",
    "    \n",
    "    def __init__(self, id_col, target_col, types):\n",
    "        assert id_col in types and target_col in types\n",
    "        self.id_col = id_col\n",
    "        self.target_col = target_col\n",
    "        self.types = types\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self.convert(*args, **kwargs)\n",
    "        \n",
    "    def convert(self, train, test, out, saver_fn=default_saver, **params):\n",
    "        types = self.types.copy()\n",
    "        trn_df = pd.read_csv(train, usecols=types.keys(), dtype=types)\n",
    "        del types[self.target_col]\n",
    "        tst_df = pd.read_csv(test, usecols=types.keys(), dtype=types)\n",
    "        data = pd.concat([trn_df, tst_df], axis=0, sort=False)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        del data[self.id_col]\n",
    "        return saver_fn(data, out, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def to_feather(train, test, out):\n",
    "    conv = Converter(id_feature, target_feature, efficient_types)\n",
    "    conv(train, test, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "to_feather(TRAIN, TEST, DATA/'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Features Encoding\n",
    "\n",
    "The next step is to encode the categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(DATA/'data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_categorical(df):\n",
    "    cols = df.columns.tolist()\n",
    "    if target_feature in cols:\n",
    "        cols.remove(target_feature)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding features:\n",
      "[ 1/81] ProductName\n",
      "[ 2/81] EngineVersion\n",
      "[ 3/81] AppVersion\n",
      "[ 4/81] AvSigVersion\n",
      "[ 5/81] IsBeta\n",
      "[ 6/81] RtpStateBitfield\n",
      "[ 7/81] IsSxsPassiveMode\n",
      "[ 8/81] DefaultBrowsersIdentifier\n",
      "[ 9/81] AVProductStatesIdentifier\n",
      "[10/81] AVProductsInstalled\n",
      "[11/81] AVProductsEnabled\n",
      "[12/81] HasTpm\n",
      "[13/81] CountryIdentifier\n",
      "[14/81] CityIdentifier\n",
      "[15/81] OrganizationIdentifier\n",
      "[16/81] GeoNameIdentifier\n",
      "[17/81] LocaleEnglishNameIdentifier\n",
      "[18/81] Platform\n",
      "[19/81] Processor\n",
      "[20/81] OsVer\n",
      "[21/81] OsBuild\n",
      "[22/81] OsSuite\n",
      "[23/81] OsPlatformSubRelease\n",
      "[24/81] OsBuildLab\n",
      "[25/81] SkuEdition\n",
      "[26/81] IsProtected\n",
      "[27/81] AutoSampleOptIn\n",
      "[28/81] PuaMode\n",
      "[29/81] SMode\n",
      "[30/81] IeVerIdentifier\n",
      "[31/81] SmartScreen\n",
      "[32/81] Firewall\n",
      "[33/81] UacLuaenable\n",
      "[34/81] Census_MDC2FormFactor\n",
      "[35/81] Census_DeviceFamily\n",
      "[36/81] Census_OEMNameIdentifier\n",
      "[37/81] Census_OEMModelIdentifier\n",
      "[38/81] Census_ProcessorCoreCount\n",
      "[39/81] Census_ProcessorManufacturerIdentifier\n",
      "[40/81] Census_ProcessorModelIdentifier\n",
      "[41/81] Census_ProcessorClass\n",
      "[42/81] Census_PrimaryDiskTotalCapacity\n",
      "[43/81] Census_PrimaryDiskTypeName\n",
      "[44/81] Census_SystemVolumeTotalCapacity\n",
      "[45/81] Census_HasOpticalDiskDrive\n",
      "[46/81] Census_TotalPhysicalRAM\n",
      "[47/81] Census_ChassisTypeName\n",
      "[48/81] Census_InternalPrimaryDiagonalDisplaySizeInInches\n",
      "[49/81] Census_InternalPrimaryDisplayResolutionHorizontal\n",
      "[50/81] Census_InternalPrimaryDisplayResolutionVertical\n",
      "[51/81] Census_PowerPlatformRoleName\n",
      "[52/81] Census_InternalBatteryType\n",
      "[53/81] Census_InternalBatteryNumberOfCharges\n",
      "[54/81] Census_OSVersion\n",
      "[55/81] Census_OSArchitecture\n",
      "[56/81] Census_OSBranch\n",
      "[57/81] Census_OSBuildNumber\n",
      "[58/81] Census_OSBuildRevision\n",
      "[59/81] Census_OSEdition\n",
      "[60/81] Census_OSSkuName\n",
      "[61/81] Census_OSInstallTypeName\n",
      "[62/81] Census_OSInstallLanguageIdentifier\n",
      "[63/81] Census_OSUILocaleIdentifier\n",
      "[64/81] Census_OSWUAutoUpdateOptionsName\n",
      "[65/81] Census_IsPortableOperatingSystem\n",
      "[66/81] Census_GenuineStateName\n",
      "[67/81] Census_ActivationChannel\n",
      "[68/81] Census_IsFlightingInternal\n",
      "[69/81] Census_IsFlightsDisabled\n",
      "[70/81] Census_FlightRing\n",
      "[71/81] Census_ThresholdOptIn\n",
      "[72/81] Census_FirmwareManufacturerIdentifier\n",
      "[73/81] Census_FirmwareVersionIdentifier\n",
      "[74/81] Census_IsSecureBootEnabled\n",
      "[75/81] Census_IsWIMBootEnabled\n",
      "[76/81] Census_IsVirtualDevice\n",
      "[77/81] Census_IsTouchEnabled\n",
      "[78/81] Census_IsPenCapable\n",
      "[79/81] Census_IsAlwaysOnAlwaysConnectedCapable\n",
      "[80/81] Wdft_IsGamer\n",
      "[81/81] Wdft_RegionIdentifier\n"
     ]
    }
   ],
   "source": [
    "print('Encoding features:')\n",
    "cat_features = get_categorical(data)\n",
    "total = len(cat_features)\n",
    "eps = int(1e-4 * len(data))\n",
    "\n",
    "for i, feature in enumerate(cat_features, 1):\n",
    "    print(f'[{i:2d}/{total:2d}] {feature}')\n",
    "    col = data[feature].astype(str)\n",
    "    encoder = LabelEncoder().fit(col.unique())\n",
    "    data[feature] = encoder.transform(col) + 1\n",
    "    rare = {val: 0 if cnt <= eps else val\n",
    "            for val, cnt in data[feature].value_counts().items()}\n",
    "    data[feature] = data[feature].map(rare).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.to_feather(DATA/'enc.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(DATA/'enc.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Counting \n",
    "\n",
    "Let's count how often a specific value is encountered, including interacations between pairs of features also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features =[ \n",
    "    'ProductName',\n",
    "    'EngineVersion',\n",
    "    'AppVersion',\n",
    "    'AvSigVersion',\n",
    "    'Platform',\n",
    "    'Processor',\n",
    "    'OsBuildLab',\n",
    "    'SmartScreen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_groups = [list(g) for g in chain(*[combinations(features, i) for i in range(1, 3)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnt_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new feature: ProductName_Freq\n",
      "Creating new feature: EngineVersion_Freq\n",
      "Creating new feature: AppVersion_Freq\n",
      "Creating new feature: AvSigVersion_Freq\n",
      "Creating new feature: Platform_Freq\n",
      "Creating new feature: Processor_Freq\n",
      "Creating new feature: OsBuildLab_Freq\n",
      "Creating new feature: SmartScreen_Freq\n",
      "Creating new feature: ProductName_EngineVersion_Freq\n",
      "Creating new feature: ProductName_AppVersion_Freq\n",
      "Creating new feature: ProductName_AvSigVersion_Freq\n",
      "Creating new feature: ProductName_Platform_Freq\n",
      "Creating new feature: ProductName_Processor_Freq\n",
      "Creating new feature: ProductName_OsBuildLab_Freq\n",
      "Creating new feature: ProductName_SmartScreen_Freq\n",
      "Creating new feature: EngineVersion_AppVersion_Freq\n",
      "Creating new feature: EngineVersion_AvSigVersion_Freq\n",
      "Creating new feature: EngineVersion_Platform_Freq\n",
      "Creating new feature: EngineVersion_Processor_Freq\n",
      "Creating new feature: EngineVersion_OsBuildLab_Freq\n",
      "Creating new feature: EngineVersion_SmartScreen_Freq\n",
      "Creating new feature: AppVersion_AvSigVersion_Freq\n",
      "Creating new feature: AppVersion_Platform_Freq\n",
      "Creating new feature: AppVersion_Processor_Freq\n",
      "Creating new feature: AppVersion_OsBuildLab_Freq\n",
      "Creating new feature: AppVersion_SmartScreen_Freq\n",
      "Creating new feature: AvSigVersion_Platform_Freq\n",
      "Creating new feature: AvSigVersion_Processor_Freq\n",
      "Creating new feature: AvSigVersion_OsBuildLab_Freq\n",
      "Creating new feature: AvSigVersion_SmartScreen_Freq\n",
      "Creating new feature: Platform_Processor_Freq\n",
      "Creating new feature: Platform_OsBuildLab_Freq\n",
      "Creating new feature: Platform_SmartScreen_Freq\n",
      "Creating new feature: Processor_OsBuildLab_Freq\n",
      "Creating new feature: Processor_SmartScreen_Freq\n",
      "Creating new feature: OsBuildLab_SmartScreen_Freq\n"
     ]
    }
   ],
   "source": [
    "for keys in feature_groups:\n",
    "    new_col = '_'.join(keys) + '_Freq'\n",
    "    print('Creating new feature:', new_col)\n",
    "    cnt = data.groupby(keys).size().to_frame(new_col).reset_index()\n",
    "    cnt_df[new_col] = pd.merge(data[keys], cnt, how='left', on=keys, suffixes=('', '.cnt'))[new_col]\n",
    "    cnt_df[new_col] = (cnt_df[new_col] / len(cnt_df)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cnt_df.to_feather(DATA/'cnt.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Tree Leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[~data[target_feature].isna()]\n",
    "y = X[target_feature].copy()\n",
    "del X[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_idx, val_idx = train_test_split(X.index, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_trn = X[X.index.isin(trn_idx)]\n",
    "x_val = X[X.index.isin(val_idx)]\n",
    "y_trn = y[y.index.isin(trn_idx)]\n",
    "y_val = y[y.index.isin(val_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trees = lgb.LGBMClassifier(n_estimators=100, colsample_bytree=0.3, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[20]\tvalid_0's auc: 0.699784\tvalid_0's binary_logloss: 0.657074\n",
      "[40]\tvalid_0's auc: 0.706507\tvalid_0's binary_logloss: 0.638369\n",
      "[60]\tvalid_0's auc: 0.710588\tvalid_0's binary_logloss: 0.627345\n",
      "[80]\tvalid_0's auc: 0.713593\tvalid_0's binary_logloss: 0.622163\n",
      "[100]\tvalid_0's auc: 0.71615\tvalid_0's binary_logloss: 0.618394\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.71615\tvalid_0's binary_logloss: 0.618394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.3,\n",
       "        importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.fit(x_trn, y_trn,\n",
    "          eval_metric='auc',\n",
    "          eval_set=[(x_val, y_val)], \n",
    "          verbose=20,\n",
    "          early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def chunks(data, chunk_size=10000):\n",
    "    n = len(data)\n",
    "    n_chunks = n//chunk_size + int(n % chunk_size != 0)\n",
    "    for i in range(n_chunks):\n",
    "        yield data.iloc[i*chunk_size:(i + 1)*chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del data[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "leafs = np.row_stack([trees.predict(chunk, pred_leaf=True) for chunk in chunks(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "leafs_df = pd.DataFrame(leafs, columns=[f'Leaf_Tree{i:d}' for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "leafs_df.to_feather(DATA/'leaf.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distance = hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors=100, metric=distance, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[~data[target_feature].isna()]\n",
    "y = X[target_feature].copy()\n",
    "del X[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "neighbours = nn.kneighbours(X, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y[neighbours]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[~data[target_feature].isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features =[ \n",
    "    'ProductName',\n",
    "    'EngineVersion',\n",
    "    'AppVersion',\n",
    "    'AvSigVersion',\n",
    "    'Platform',\n",
    "    'Processor',\n",
    "    'OsBuildLab',\n",
    "    'SmartScreen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n, rounds = len(X), 3\n",
    "global_mean = X[target_feature].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean encoding feature: ProductName_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: EngineVersion_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: AppVersion_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: AvSigVersion_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: Platform_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: Processor_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: OsBuildLab_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n",
      "Mean encoding feature: SmartScreen_MeanTarget\n",
      "\tround: 0.. 1.. 2.. \n"
     ]
    }
   ],
   "source": [
    "for feat in features:\n",
    "    name = f'{feat}_MeanTarget'\n",
    "    X[name] = 0\n",
    "    print(f'Mean encoding feature:', name)\n",
    "    print('\\tround:', end=' ')\n",
    "    for i in range(rounds):\n",
    "        print(f'{i}..', end=' ')\n",
    "        perm = X[X.index.isin(np.random.choice(n, size=n, replace=False))]\n",
    "        cumsum = perm.groupby(feat)[target_feature].cumsum() - perm[target_feature]\n",
    "        cumcnt = perm.groupby(feat)[target_feature].cumcount()\n",
    "        X[name] += (cumsum/cumcnt).fillna(global_mean)\n",
    "    X[name] /= rounds\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = data[~data.index.isin(X.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test set values for the mean feature: ProductName_MeanTarget\n",
      "Generating test set values for the mean feature: EngineVersion_MeanTarget\n",
      "Generating test set values for the mean feature: AppVersion_MeanTarget\n",
      "Generating test set values for the mean feature: AvSigVersion_MeanTarget\n",
      "Generating test set values for the mean feature: Platform_MeanTarget\n",
      "Generating test set values for the mean feature: Processor_MeanTarget\n",
      "Generating test set values for the mean feature: OsBuildLab_MeanTarget\n",
      "Generating test set values for the mean feature: SmartScreen_MeanTarget\n"
     ]
    }
   ],
   "source": [
    "for feat in features:\n",
    "    name = f'{feat}_MeanTarget'\n",
    "    print('Generating test set values for the mean feature:', name)\n",
    "    train_groups = X.groupby(feat).groups\n",
    "    train_keys = list(train_groups)\n",
    "    test_keys = list(X_test.groupby(feat).groups)\n",
    "    for key in test_keys:\n",
    "        subset = X_test[feat] == key\n",
    "        if key not in train_keys or len(train_groups[key]) == 0:\n",
    "            X_test.loc[subset, name] = global_mean\n",
    "        else:\n",
    "            sample = X[name][train_groups[key]].sample(subset.sum(), replace=True)\n",
    "            X_test.loc[subset, name] = sample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([X, X_test], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_df = data[data.columns[data.columns.str.endswith('MeanTarget')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_df = mean_df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_df.to_feather('mean.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enc = feather.read_dataframe(DATA/'enc.feather')\n",
    "cnt = feather.read_dataframe(DATA/'cnt.feather').astype(np.float16)\n",
    "mean = feather.read_dataframe(DATA/'mean.feather').astype(np.float16)\n",
    "leafs = feather.read_dataframe(DATA/'leaf.feather').astype('category')\n",
    "data = pd.concat([enc, cnt, mean, leafs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_df = data.loc[~data[target_feature].isna()]\n",
    "tst_df = data.loc[ data[target_feature].isna()]\n",
    "trn_target = trn_df[target_feature].copy()\n",
    "del trn_df[target_feature], tst_df[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = trn_df.astype(np.float16).values\n",
    "y = trn_target.astype(np.uint8).values\n",
    "X_test = tst_df.astype(np.float16).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file: /home/ck/data/microsoft/x_train.npy\n",
      "Saving file: /home/ck/data/microsoft/y_train.npy\n",
      "Saving file: /home/ck/data/microsoft/x_test.npy\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    ('x_train', X),\n",
    "    ('y_train', y),\n",
    "    ('x_test', X_test)]\n",
    "\n",
    "for name, arr in files:\n",
    "    filename = DATA/f'{name}.npy'\n",
    "    print('Saving file:', filename)\n",
    "    np.save(filename, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, target, n_splits=5, seed=seed):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    idx = np.arange(len(data))\n",
    "    for i, (trn_idx, val_idx) in enumerate(kfold.split(idx, target), 1):\n",
    "        print(f'Running {i:d} of {kfold.get_n_splits():d} folds')\n",
    "        yield trn_idx, val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(DATA/'x_train.npy')\n",
    "y = np.load(DATA/'y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'colsample_bytree': 0.25,\n",
    "    'learning_rate': 0.10, # 0.05\n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 500,\n",
    "    'n_estimators': 10000,\n",
    "    'objective': 'binary',\n",
    "    'random_state': seed,\n",
    "    'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 of 5 folds\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[125]\tvalid_0's auc: 0.73726\tvalid_0's binary_logloss: 0.596944\n",
      "[250]\tvalid_0's auc: 0.740404\tvalid_0's binary_logloss: 0.594358\n",
      "[375]\tvalid_0's auc: 0.740929\tvalid_0's binary_logloss: 0.593904\n",
      "[500]\tvalid_0's auc: 0.741173\tvalid_0's binary_logloss: 0.593697\n",
      "[625]\tvalid_0's auc: 0.741358\tvalid_0's binary_logloss: 0.593526\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's auc: 0.741368\tvalid_0's binary_logloss: 0.593518\n",
      "Predicting validation fold...\n",
      "Fold time: 00:10:16\n",
      "Running 2 of 5 folds\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[125]\tvalid_0's auc: 0.738138\tvalid_0's binary_logloss: 0.596234\n",
      "[250]\tvalid_0's auc: 0.741204\tvalid_0's binary_logloss: 0.59367\n",
      "[375]\tvalid_0's auc: 0.74189\tvalid_0's binary_logloss: 0.593063\n",
      "[500]\tvalid_0's auc: 0.742143\tvalid_0's binary_logloss: 0.59284\n",
      "[625]\tvalid_0's auc: 0.742192\tvalid_0's binary_logloss: 0.592785\n",
      "Early stopping, best iteration is:\n",
      "[585]\tvalid_0's auc: 0.742216\tvalid_0's binary_logloss: 0.592771\n",
      "Predicting validation fold...\n",
      "Fold time: 00:10:06\n",
      "Running 3 of 5 folds\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[125]\tvalid_0's auc: 0.737659\tvalid_0's binary_logloss: 0.596599\n",
      "[250]\tvalid_0's auc: 0.74062\tvalid_0's binary_logloss: 0.594122\n",
      "[375]\tvalid_0's auc: 0.741238\tvalid_0's binary_logloss: 0.593591\n",
      "[500]\tvalid_0's auc: 0.741532\tvalid_0's binary_logloss: 0.593337\n",
      "[625]\tvalid_0's auc: 0.741637\tvalid_0's binary_logloss: 0.593251\n",
      "Early stopping, best iteration is:\n",
      "[608]\tvalid_0's auc: 0.741645\tvalid_0's binary_logloss: 0.593232\n",
      "Predicting validation fold...\n",
      "Fold time: 00:10:22\n",
      "Running 4 of 5 folds\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[125]\tvalid_0's auc: 0.73788\tvalid_0's binary_logloss: 0.596455\n",
      "[250]\tvalid_0's auc: 0.740848\tvalid_0's binary_logloss: 0.593987\n",
      "[375]\tvalid_0's auc: 0.741434\tvalid_0's binary_logloss: 0.593486\n",
      "[500]\tvalid_0's auc: 0.741672\tvalid_0's binary_logloss: 0.593273\n",
      "[625]\tvalid_0's auc: 0.741831\tvalid_0's binary_logloss: 0.593131\n",
      "[750]\tvalid_0's auc: 0.741878\tvalid_0's binary_logloss: 0.593101\n",
      "Early stopping, best iteration is:\n",
      "[716]\tvalid_0's auc: 0.741914\tvalid_0's binary_logloss: 0.593072\n",
      "Predicting validation fold...\n",
      "Fold time: 00:11:09\n",
      "Running 5 of 5 folds\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[125]\tvalid_0's auc: 0.73743\tvalid_0's binary_logloss: 0.596791\n",
      "[250]\tvalid_0's auc: 0.740372\tvalid_0's binary_logloss: 0.594315\n",
      "[375]\tvalid_0's auc: 0.740929\tvalid_0's binary_logloss: 0.593833\n",
      "[500]\tvalid_0's auc: 0.741175\tvalid_0's binary_logloss: 0.59361\n",
      "[625]\tvalid_0's auc: 0.741233\tvalid_0's binary_logloss: 0.593578\n",
      "[750]\tvalid_0's auc: 0.741292\tvalid_0's binary_logloss: 0.593541\n",
      "Early stopping, best iteration is:\n",
      "[726]\tvalid_0's auc: 0.741305\tvalid_0's binary_logloss: 0.593528\n",
      "Predicting validation fold...\n",
      "Fold time: 00:11:10\n",
      "Total amount of training time: 00:53:06\n"
     ]
    }
   ],
   "source": [
    "val_lgb = np.zeros(len(X), dtype=np.float16)\n",
    "ensemble = []\n",
    "total_time = 0\n",
    "for trn_idx, val_idx in split(X, y):\n",
    "    with Timer() as timer:\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X[trn_idx], y[trn_idx],\n",
    "            eval_metric='auc',\n",
    "            eval_set=[(X[val_idx], y[val_idx])],\n",
    "            verbose=125, early_stopping_rounds=125)\n",
    "        print('Predicting validation fold...')\n",
    "        val_lgb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "    print(f'Fold time: {timer}')\n",
    "    ensemble.append(model)\n",
    "    total_time += float(timer)\n",
    "print(f'Total amount of training time: {Timer.format_elapsed_time(total_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ck/data/microsoft/lgb_ensemble.pickle']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ensemble, DATA/'lgb_ensemble.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(DATA/'x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = np.zeros(len(X_test), dtype=np.float16)\n",
    "for model in ensemble:\n",
    "    test_result += model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result /= len(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(DATA/'sample_submission.csv')\n",
    "submit['HasDetections'] = test_result\n",
    "submit.to_csv('lgb_cv.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 297M/297M [00:36<00:00, 8.60MB/s]\n",
      "Successfully submitted to Microsoft Malware Prediction"
     ]
    }
   ],
   "source": [
    "!kaggle c submit -c microsoft-malware-prediction -f \"lgb_cv.csv\" -m \"LightGBM CV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA/'lgb_cv.npy', test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(DATA/'x_train.npy')\n",
    "y = np.load(DATA/'y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 391M/391M [00:39<00:00, 10.4MB/s]\n",
      "Successfully submitted to Microsoft Malware Prediction"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'bagging_temperature': 1.8,\n",
    "    'l2_leaf_reg': 1,\n",
    "    'leaf_estimation_method': 'Gradient',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.6,\n",
    "    'iterations': 30000,\n",
    "    'bootstrap_type': 'Poisson',\n",
    "    'eval_metric': 'AUC',\n",
    "    'task_type': 'GPU',\n",
    "    'devices': '0:1',\n",
    "    'loss_function': 'CrossEntropy',\n",
    "    'logging_level': 'Verbose',\n",
    "    'random_seed': seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cb = np.zeros(len(X), dtypes=np.float16)\n",
    "ensemble = []\n",
    "for trn_idx, val_idx in split(X, y):\n",
    "    model = cb.CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X[trn_idx], y[trn_idx],\n",
    "        eval_set=[(X[val_idx], y[val_idx])],\n",
    "        metric_period=250, early_stopping_rounds=250)\n",
    "    print('Predicting validation fold...')\n",
    "    val_cb[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
    "    ensemble.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ensemble, DATA/'cb_ensemble.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(DATA/'x_train.npy')\n",
    "y = np.load(DATA/'y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'loss': 'exponential',\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 35,\n",
    "    'max_features': 'sqrt',\n",
    "    'n_iter_no_change': 100,\n",
    "    'verbose': 1,\n",
    "    'random_state': seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gb = np.zeros(len(X), dtypes=np.float16)\n",
    "ensemble = []\n",
    "for trn_idx, val_idx in split(X, y):\n",
    "    def monitor(i, self, local_vars):\n",
    "        y_hat = self.predict_proba(X[val_idx])[:, 1]\n",
    "        auc()\n",
    "        \n",
    "    model = GradientBoostingClassifier(**params)\n",
    "    model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Them All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(DATA/'x_train.npy')\n",
    "y = np.load(DATA/'y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load(DATA/'lgb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict_proba(np.load(DATA/'x_test.npy'))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv(DATA/'sample_submission.csv')\n",
    "# submit['HasDetections'] = preds\n",
    "# submit.to_csv('lgb.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle c submit -c microsoft-malware-prediction -f \"lgb.csv\" -m \"LightGBM with a ton of features\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
