{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import gc\n",
    "\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_summary import DataFrameSummary\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "\n",
    "from basedir import DATA, TRAIN, TEST\n",
    "from info import efficient_types, cat_features, num_features, id_feature, target_feature\n",
    "from utils import show_all_columns, show_all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(1)\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA/'data.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(df):\n",
    "    stats = DataFrameSummary(df).columns_stats.T\n",
    "    for column in ('counts', 'uniques', 'missing'):\n",
    "        stats[column] = stats[column].astype(np.int32)\n",
    "    stats['missing_perc'] = stats['missing_perc'].map(lambda s: float(s.strip('%'))/100)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists():\n",
    "    print('Loading HDF5 data...')\n",
    "    trn_df = pd.read_hdf(path, key='train')\n",
    "    tst_df = pd.read_hdf(path, key='test')\n",
    "    trn_stats = pd.read_hdf(path, key='train_stats')\n",
    "    tst_stats = pd.read_hdf(path, key='test_stats')\n",
    "else:\n",
    "    print('Loading CSV files...')\n",
    "    trn_df = pd.read_csv(TRAIN, usecols=efficient_types.keys(), dtype=efficient_types)\n",
    "    trn_df.drop(columns=[id_feature], inplace=True)\n",
    "    test_types = efficient_types.copy()\n",
    "    del test_types[target_feature]\n",
    "    tst_df = pd.read_csv(TEST, usecols=test_types, dtype=test_types)\n",
    "    print('Computing summary stats...')\n",
    "    trn_stats = compute_stats(trn_df)\n",
    "    tst_stats = compute_stats(tst_df)\n",
    "    print('Saving the prepared files into HDF5 format...')\n",
    "    trn_df.to_hdf(path, key='train', format='table')\n",
    "    tst_df.to_hdf(path, key='test', format='table')\n",
    "    trn_stats.to_hdf(path, key='train_stats', format='table')\n",
    "    tst_stats.to_hdf(path, key='test_stats', format='table')\n",
    "print('The data is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = trn_df[num_features].corr().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cm, annot=True, fmt='2.2f')\n",
    "ax.set_xticklabels(num_features, rotation=90)\n",
    "ax.set_yticklabels(num_features, rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = trn_df[target_feature]\n",
    "trn_df.drop(columns=[target_feature], inplace=True)\n",
    "trn_df['Subset'] = 'Train'\n",
    "tst_df['Subset'] = 'Test'\n",
    "traintest = pd.concat([trn_df, tst_df], axis=0, sort=True, ignore_index=True)\n",
    "cat_feat = traintest[cat_features + ['Subset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all_rows(cat_feat.sample(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trn_df, tst_df, traintest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching features with similar values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(cat_feat['Census_OSArchitecture'], cat_feat['Processor'])\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = cat_feat['Processor']\n",
    "census_os = cat_feat['Census_OSArchitecture']\n",
    "arch_type = np.array(['other'] * len(cat_feat), dtype='object')\n",
    "arch_type[(proc == 'x64') & (census_os == 'amd64')] = 'x64'\n",
    "arch_type[(proc == 'x86') & (census_os == 'x86')] = 'x86'\n",
    "del proc, census_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['AdjustedArchType'] = pd.Categorical(arch_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_key, edi_key = keys = ['Census_OSSkuName', 'Census_OSEdition']\n",
    "sku_cnt, edi_cnt = [cat_feat[col].value_counts() for col in keys]\n",
    "sku_freq, edi_freq = [{k for k, v in cnt.items() if v >= 1000} for cnt in (sku_cnt, edi_cnt)]\n",
    "freq = cat_feat[cat_feat[sku_key].isin(sku_freq) & cat_feat[edi_key].isin(edi_freq)][keys]\n",
    "ct = pd.crosstab(freq[sku_key], freq[edi_key]).apply(lambda r: r/r.sum(), axis=1)\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "ax.set_aspect('equal')\n",
    "sns.heatmap(ct, annot=True, fmt='2.3f', ax=ax)\n",
    "\n",
    "pairs = {}\n",
    "for j, col in enumerate(ct.columns):\n",
    "    for i, row in enumerate(ct.index):\n",
    "        pairs[(row, col)] = ct.values[i, j]\n",
    "\n",
    "pairs = list(pairs.items())\n",
    "pairs.sort(key=lambda pair: pair[-1], reverse=True)\n",
    "most_confident = [k for k, v in pairs if v > 0.9]\n",
    "\n",
    "filters = [\n",
    "    (cat_feat[sku_key] == sku) & (cat_feat[edi_key] == edi) \n",
    "    for sku, edi in most_confident]\n",
    "filters = reduce(lambda a, b: a | b, filters)\n",
    "\n",
    "os_type = np.array(['Other'] * len(cat_feat), dtype=object)\n",
    "nulls = pd.isnull(cat_feat[sku_key]) | pd.isnull(cat_feat[edi_key])\n",
    "os_type[filters] = cat_feat[filters][edi_key]\n",
    "os_type[nulls] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['AdjustedOSType'] = os_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['AdjustedOSType'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more boolean features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['ProductName'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['IsDefender'] = (cat_feat['ProductName'] == 'win8defender').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['SkuEdition'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['IsHome'] = (cat_feat['SkuEdition'] == 'Home').astype(np.uint8)\n",
    "cat_feat['IsWork'] = (~cat_feat['SkuEdition'].isin(['Home', 'Education', 'Invalid'])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['Census_DeviceFamily'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['IsDesktop'] = (cat_feat['Census_DeviceFamily'] == 'Windows.Desktop').astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat['Census_PrimaryDiskTypeName'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.isnull(cat_feat['Census_PrimaryDiskTypeName'])\n",
    "disk_map = defaultdict(lambda: 'other')\n",
    "disk_map.update({'SSD': 'ssd', 'HDD': 'hdd'})\n",
    "disk_type = cat_feat['Census_PrimaryDiskTypeName'].map(disk_map)\n",
    "disk_type[nulls] = np.nan\n",
    "cat_feat['DiskType'] = pd.Categorical(disk_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_type.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Compund Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(col):\n",
    "    return list(zip(*col.str.split('.').tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_version(df, column):\n",
    "    major, minor, build, release = split_str(df[column])\n",
    "    columns = [('Major', major),\n",
    "               ('Minor', minor),\n",
    "               ('Build', build),\n",
    "               ('Release', release)]\n",
    "    print(f'Unique values for column \\'{column}\\'')\n",
    "    for name, version in columns:\n",
    "        print(f'{name}: {len(set(version))}')\n",
    "    expanded = pd.DataFrame({\n",
    "        f'{column}_{suffix}': pd.Categorical(col) \n",
    "        for suffix, col in columns})\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_df = pd.concat([\n",
    "    split_version(cat_feat, 'EngineVersion'),\n",
    "    split_version(cat_feat, 'AppVersion'),\n",
    "    split_version(cat_feat, 'AvSigVersion'),\n",
    "    split_version(cat_feat, 'Census_OSVersion')\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ver_df.columns:\n",
    "    cat_feat[column] = ver_df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ver_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feat.to_pickle('prepared.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feat = pd.read_pickle('prepared.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special treatment for OsBuildLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_str):\n",
    "    try:\n",
    "        date_str, _ = date_str.split('-')\n",
    "        date_obj = datetime.strptime(date_str, '%y%m%d')\n",
    "    except ValueError:\n",
    "        return (0, 0, 0)\n",
    "    return (date_obj.year, date_obj.month, date_obj.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(column, item):\n",
    "    return column.str.replace('*', '.').str.split('.').map(lambda x: x[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(column, item):    \n",
    "    return (\n",
    "        extract(column, -1)\n",
    "        .map(parse_date)\n",
    "        .map(lambda triple: triple[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null = ~pd.isnull(cat_feat['OsBuildLab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, suffix in enumerate(['Major', 'Minor', 'Branch', 'Release']):\n",
    "    name = f'OsBuildLab_{suffix}'\n",
    "    print('Creating feature:', name)\n",
    "    cat_feat[name] = np.nan\n",
    "    cat_feat.loc[not_null, name] = extract(cat_feat['OsBuildLab'][not_null], i)\n",
    "    cat_feat[name] = pd.Categorical(cat_feat[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, suffix in enumerate(['Year', 'Month', 'Day']):\n",
    "    name = f'OsBuildLab_{suffix}'\n",
    "    print('Creating feature:', name)\n",
    "    cat_feat[name] = np.nan\n",
    "    cat_feat.loc[not_null, name] = extract_date(cat_feat['OsBuildLab'][not_null], i)\n",
    "    cat_feat[name] = pd.Categorical(cat_feat[name], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat.to_pickle('prepared.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = pd.read_pickle('prepared.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = cat_feat.columns.tolist()\n",
    "n = len(columns)\n",
    "for i, column in enumerate(columns, 1):\n",
    "    if column == 'Subset':\n",
    "        continue\n",
    "    print(f'Encoding column [{i:2d}/{n:2d}]:', column)\n",
    "    na = pd.isnull(cat_feat[column])  # filter NaNs before converting into strings\n",
    "    cat_feat[column] = col = cat_feat[column].astype(str)\n",
    "    uniqs = col[~na].unique()\n",
    "    cat_feat.loc[~na, column] = LabelEncoder().fit(uniqs).transform(col[~na]) + 1\n",
    "    cat_feat.loc[ na, column] = 0\n",
    "    cat_feat[column] = pd.Categorical(cat_feat[column].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_all_columns(cat_feat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat.to_pickle('final.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = pd.read_pickle('final.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>EngineVersion</th>\n",
       "      <th>AppVersion</th>\n",
       "      <th>AvSigVersion</th>\n",
       "      <th>IsBeta</th>\n",
       "      <th>RtpStateBitfield</th>\n",
       "      <th>IsSxsPassiveMode</th>\n",
       "      <th>DefaultBrowsersIdentifier</th>\n",
       "      <th>AVProductStatesIdentifier</th>\n",
       "      <th>AVProductsInstalled</th>\n",
       "      <th>...</th>\n",
       "      <th>Census_OSVersion_Minor</th>\n",
       "      <th>Census_OSVersion_Build</th>\n",
       "      <th>Census_OSVersion_Release</th>\n",
       "      <th>OsBuildLab_Major</th>\n",
       "      <th>OsBuildLab_Minor</th>\n",
       "      <th>OsBuildLab_Branch</th>\n",
       "      <th>OsBuildLab_Release</th>\n",
       "      <th>OsBuildLab_Year</th>\n",
       "      <th>OsBuildLab_Month</th>\n",
       "      <th>OsBuildLab_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15042384</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>8794</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26978</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>181</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896353</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>8877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29199</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>276</td>\n",
       "      <td>32</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620478</th>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>8251</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26978</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>214</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14395308</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>8901</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26978</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>264</td>\n",
       "      <td>32</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132974</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>7755</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26978</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>242</td>\n",
       "      <td>32</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ProductName EngineVersion AppVersion AvSigVersion IsBeta  \\\n",
       "15042384           5            70         65         8794      1   \n",
       "11896353           5            68         67         8877      1   \n",
       "4620478            5            68         65         8251      1   \n",
       "14395308           5            70         67         8901      1   \n",
       "4132974            5            67         59         7755      1   \n",
       "\n",
       "         RtpStateBitfield IsSxsPassiveMode DefaultBrowsersIdentifier  \\\n",
       "15042384                7                1                         0   \n",
       "11896353                1                2                         0   \n",
       "4620478                 7                1                         0   \n",
       "14395308                7                1                         0   \n",
       "4132974                 7                1                         0   \n",
       "\n",
       "         AVProductStatesIdentifier AVProductsInstalled      ...        \\\n",
       "15042384                     26978                   2      ...         \n",
       "11896353                     29199                   3      ...         \n",
       "4620478                      26978                   2      ...         \n",
       "14395308                     26978                   2      ...         \n",
       "4132974                      26978                   2      ...         \n",
       "\n",
       "         Census_OSVersion_Minor Census_OSVersion_Build  \\\n",
       "15042384                      1                    122   \n",
       "11896353                      1                    102   \n",
       "4620478                       1                    122   \n",
       "14395308                      1                    102   \n",
       "4132974                       1                    102   \n",
       "\n",
       "         Census_OSVersion_Release OsBuildLab_Major OsBuildLab_Minor  \\\n",
       "15042384                      181               34                2   \n",
       "11896353                      276               32              283   \n",
       "4620478                       214               34                2   \n",
       "14395308                      264               32              283   \n",
       "4132974                       242               32              283   \n",
       "\n",
       "         OsBuildLab_Branch OsBuildLab_Release OsBuildLab_Year  \\\n",
       "15042384                 1                 16              11   \n",
       "11896353                 1                 13              11   \n",
       "4620478                  1                 16              11   \n",
       "14395308                 1                 13              11   \n",
       "4132974                  1                 13              11   \n",
       "\n",
       "         OsBuildLab_Month OsBuildLab_Day  \n",
       "15042384                8              3  \n",
       "11896353                9             13  \n",
       "4620478                 8              3  \n",
       "14395308                9             13  \n",
       "4132974                 9             13  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feat.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump to the Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cat_feat[cat_feat.Subset == 'Train'].copy()\n",
    "train[target_feature] = trn_df[target_feature].tolist()\n",
    "test = cat_feat[cat_feat.Subset == 'Test'].copy()\n",
    "del train['Subset'], test['Subset'], cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATA/'prep.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_hdf(path, key='train', format='table')\n",
    "test.to_hdf(path, key='test', format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_hdf(path, key='train')\n",
    "tst_df = pd.read_hdf(path, key='test')\n",
    "target = trn_df[target_feature]\n",
    "del trn_df[target_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold: 1 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600118\tvalid_0's auc: 0.733871\n",
      "[200]\tvalid_0's binary_logloss: 0.598002\tvalid_0's auc: 0.735726\n",
      "[300]\tvalid_0's binary_logloss: 0.597791\tvalid_0's auc: 0.7359\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.597727\tvalid_0's auc: 0.735989\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 2 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599782\tvalid_0's auc: 0.734639\n",
      "[200]\tvalid_0's binary_logloss: 0.597666\tvalid_0's auc: 0.736429\n",
      "[300]\tvalid_0's binary_logloss: 0.597514\tvalid_0's auc: 0.736564\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.597454\tvalid_0's auc: 0.736636\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 3 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599462\tvalid_0's auc: 0.734769\n",
      "[200]\tvalid_0's binary_logloss: 0.597459\tvalid_0's auc: 0.736425\n",
      "[300]\tvalid_0's binary_logloss: 0.597292\tvalid_0's auc: 0.736545\n",
      "[400]\tvalid_0's binary_logloss: 0.597496\tvalid_0's auc: 0.736315\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid_0's binary_logloss: 0.597205\tvalid_0's auc: 0.736672\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 4 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600013\tvalid_0's auc: 0.734619\n",
      "[200]\tvalid_0's binary_logloss: 0.597355\tvalid_0's auc: 0.736823\n",
      "[300]\tvalid_0's binary_logloss: 0.597174\tvalid_0's auc: 0.736924\n",
      "[400]\tvalid_0's binary_logloss: 0.597333\tvalid_0's auc: 0.73679\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's binary_logloss: 0.597098\tvalid_0's auc: 0.737036\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 5 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599415\tvalid_0's auc: 0.734934\n",
      "[200]\tvalid_0's binary_logloss: 0.597155\tvalid_0's auc: 0.736868\n",
      "[300]\tvalid_0's binary_logloss: 0.597006\tvalid_0's auc: 0.73699\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.59693\tvalid_0's auc: 0.737087\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 6 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599885\tvalid_0's auc: 0.734338\n",
      "[200]\tvalid_0's binary_logloss: 0.597738\tvalid_0's auc: 0.736237\n",
      "[300]\tvalid_0's binary_logloss: 0.59754\tvalid_0's auc: 0.73639\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's binary_logloss: 0.597492\tvalid_0's auc: 0.73645\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 7 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.600466\tvalid_0's auc: 0.733645\n",
      "[200]\tvalid_0's binary_logloss: 0.597804\tvalid_0's auc: 0.735913\n",
      "[300]\tvalid_0's binary_logloss: 0.597677\tvalid_0's auc: 0.735954\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's binary_logloss: 0.59763\tvalid_0's auc: 0.736026\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 8 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.598933\tvalid_0's auc: 0.735771\n",
      "[200]\tvalid_0's binary_logloss: 0.596694\tvalid_0's auc: 0.737664\n",
      "[300]\tvalid_0's binary_logloss: 0.596466\tvalid_0's auc: 0.737826\n",
      "[400]\tvalid_0's binary_logloss: 0.596766\tvalid_0's auc: 0.737495\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's binary_logloss: 0.59641\tvalid_0's auc: 0.737904\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 9 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599635\tvalid_0's auc: 0.734589\n",
      "[200]\tvalid_0's binary_logloss: 0.597556\tvalid_0's auc: 0.736415\n",
      "[300]\tvalid_0's binary_logloss: 0.597414\tvalid_0's auc: 0.736527\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.597343\tvalid_0's auc: 0.736623\n",
      "Fold AUC score: 0.74\n",
      "Running fold: 10 of 10\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.599896\tvalid_0's auc: 0.734427\n",
      "[200]\tvalid_0's binary_logloss: 0.597827\tvalid_0's auc: 0.736187\n",
      "[300]\tvalid_0's binary_logloss: 0.597722\tvalid_0's auc: 0.736243\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.597666\tvalid_0's auc: 0.73636\n",
      "Fold AUC score: 0.74\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "kfold = StratifiedKFold(n_splits=n, shuffle=True, random_state=seed)\n",
    "index = trn_df.index.tolist()\n",
    "preds = np.zeros(len(tst_df), dtype=np.float32)\n",
    "for i, (trn_idx, val_idx) in enumerate(kfold.split(index, target)):\n",
    "    print(f'Running fold: {i+1:d} of {n:d}')\n",
    "    x_trn, y_trn = trn_df.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    x_val, y_val = trn_df.iloc[val_idx], target.iloc[val_idx]\n",
    "    model = lgb.LGBMClassifier(n_estimators=30000, \n",
    "                               num_leaves=300, \n",
    "                               learning_rate=0.1,\n",
    "                               objetive='binary',\n",
    "                               random_state=seed,\n",
    "                               colsample_bytree=0.3)\n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_metric='auc',\n",
    "              eval_set=[(x_val, y_val)], \n",
    "              verbose=100,\n",
    "              early_stopping_rounds=100)\n",
    "    y_val_prob = model.predict_proba(x_val)\n",
    "    score = roc_auc_score(y_val, y_val_prob[:, 1])\n",
    "    print(f'Fold AUC score: {score:2.2f}')\n",
    "    y_prob = model.predict_proba(tst_df)\n",
    "    preds += y_prob[:, 1]\n",
    "    del x_trn, y_trn, x_val, y_val\n",
    "preds /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(DATA/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['HasDetections'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('eda_sanity_check.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feat.drop(columns=[\n",
    "#     'Census_OSArchitecture',\n",
    "#     'Processor',\n",
    "#     'Census_OSSkuName',\n",
    "#     'Census_OSEdition',\n",
    "#     'ProductName',\n",
    "#     'Census_DeviceFamily',\n",
    "#     'Census_PrimaryDiskTypeName',\n",
    "#     'EngineVersion',\n",
    "#     'AppVersion',\n",
    "#     'AvSigVersion',\n",
    "#     'Census_OSVersion',\n",
    "#     'OsBuildLab'\n",
    "# ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = SpectralBiclustering(n_clusters=2, random_state=seed)\n",
    "# cluster.fit(cm)\n",
    "# rows = np.argsort(cluster.row_labels_)\n",
    "# cols = np.argsort(cluster.column_labels_)\n",
    "# sorted_cm = cm[rows]\n",
    "# sorted_cm = cm[:, cols]\n",
    "# sorted_cm = cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
