{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is a copy of [this kernel](https://www.kaggle.com/bogorodvo/lightgbm-all-as-category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pprint import pprint, pformat\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, Trials\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from basedir import TRAIN, TEST, DATA\n",
    "from info import features, efficient_types, target_feature, id_feature\n",
    "from utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "PREPARE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_counts(df, val_col, id_col, label):\n",
    "    return df.groupby(val_col).agg({id_col: 'count'}).reset_index().rename({id_col: label}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_examples_with_nulls(df, cnt, col):\n",
    "    merged = pd.merge(df[[col]], cnt[[col, f'{col}Copy']], on=col, how='left')[f'{col}Copy']\n",
    "    return merged.replace(np.nan, 0).astype(np.int).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPARE:\n",
    "    print('Reading the data from CSV files...')\n",
    "    trn_df = pd.read_csv(TRAIN, usecols=efficient_types.keys(), dtype=efficient_types)\n",
    "    trn_df[id_feature] = trn_df.index.astype('uint32')\n",
    "    test_types = efficient_types.copy()\n",
    "    del test_types[target_feature]\n",
    "    tst_df = pd.read_csv(TEST, usecols=test_types.keys(), dtype=test_types)\n",
    "    tst_df[id_feature] = tst_df.index.astype('uint32')\n",
    "\n",
    "    print('Preparing data for training')\n",
    "    total = len(features)\n",
    "    for i, feature in enumerate(features):\n",
    "        print('[%02d/%02d] %s' % (i+1, total, feature))\n",
    "        train, test = [df[feature].astype(str) for df in (trn_df, tst_df)]\n",
    "        uniqs = train.unique().tolist() + test.unique().tolist()\n",
    "        encoder = LabelEncoder().fit(uniqs)\n",
    "        trn_df[feature] = encoder.transform(train) + 1\n",
    "        tst_df[feature] = encoder.transform(test) + 1\n",
    "        trn_cnt = compute_counts(trn_df, feature, id_feature, 'Train')\n",
    "        tst_cnt = compute_counts(tst_df, feature, id_feature, 'Test')\n",
    "        cnt = pd.merge(trn_cnt, tst_cnt, on=feature, how='outer').replace(np.nan, 0)\n",
    "        cnt = cnt[cnt['Train'] > 1000].reset_index(drop=True)\n",
    "        cnt['Total'] = cnt['Train'] + cnt['Test']\n",
    "        cnt['TrainRatio'] = cnt['Train'] / cnt['Total']\n",
    "        cnt = cnt[(cnt.TrainRatio > 0.2) & (cnt.TrainRatio < 0.8)]\n",
    "        cnt[f'{feature}Copy'] = cnt[feature]\n",
    "        trn_df[feature] = replace_rare_examples_with_nulls(trn_df, cnt, feature)\n",
    "        tst_df[feature] = replace_rare_examples_with_nulls(tst_df, cnt, feature)\n",
    "\n",
    "    trn_df.to_hdf('cat.hdf5', key='train', format='table')\n",
    "    tst_df.to_hdf('cat.hdf5', key='test', format='table')\n",
    "    \n",
    "else:\n",
    "    print('Loading previously prepared data')\n",
    "    trn_df = pd.read_hdf(DATA/'cat.hdf5', key='train')\n",
    "    tst_df = pd.read_hdf(DATA/'cat.hdf5', key='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4589"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_target = trn_df[target_feature]\n",
    "del trn_df[target_feature], trn_df[id_feature], tst_df[id_feature]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "def add_to(space, label, func, *args):\n",
    "    space[label] = func(label, *args)\n",
    "\n",
    "space = {}\n",
    "add_to(space, 'max_depth', hp.choice, [-1, hp.quniform('limited', 2, 10, 1)])\n",
    "add_to(space, 'cat_l2', hp.uniform, 8, 15)\n",
    "add_to(space, 'learning_rate', hp.uniform, 0.1, 0.5)\n",
    "add_to(space, 'colsample_bytree', hp.uniform, 0.1, 0.5)\n",
    "# add_to(space, 'boosting_type', hp.choice, ['gbdt', 'rf', 'dart', 'goss'])\n",
    "add_to(space, 'num_leaves', hp.quniform, 31, 500, 1)\n",
    "# add_to(space, 'feature_fraction', hp.uniform, 0.5, 0.95)\n",
    "\n",
    "fixed_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'random_seed': seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Trial 1/50 parameters:\n",
      "{'cat_l2': 0.6699774084852881,\n",
      " 'colsample_bytree': 0.19355369324449057,\n",
      " 'learning_rate': 0.48901865765212005,\n",
      " 'max_depth': -1,\n",
      " 'metric': 'auc',\n",
      " 'n_jobs': -1,\n",
      " 'num_leaves': 143,\n",
      " 'objective': 'binary',\n",
      " 'random_seed': 1}\n"
     ]
    }
   ],
   "source": [
    "max_evals = 50\n",
    "curr_eval = 0\n",
    "data = lgb.Dataset(trn_df, trn_target)\n",
    "\n",
    "def objective(params):\n",
    "    nonlocal curr_eval\n",
    "    curr_eval += 1\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params.update(fixed_params)\n",
    "    print('-' * 80)\n",
    "    print(f'Trial {curr_eval:d}/{max_evals:d} parameters:\\n{pformat(params)}')\n",
    "    with Timer() as timer:\n",
    "        result = lgb.cv(\n",
    "            params, data,\n",
    "            num_boost_round=1000,\n",
    "            verbose_eval=100, nfold=3, \n",
    "            early_stopping_rounds=100)\n",
    "    print(f'Execution time: {timer}')\n",
    "    return {'loss': result['auc-mean']}\n",
    "    \n",
    "best = hyperopt.fmin(\n",
    "    objective,\n",
    "    space=space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6\n",
    "split = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "test_result = np.zeros(len(tst_df))\n",
    "n = split.get_n_splits(trn_df.index, trn_target)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(split.split(trn_df.index, trn_target), 1):\n",
    "    print('Running split %02d/%02d' % (i, n))\n",
    "    x_trn = trn_df[trn_df.index.isin(trn_idx)]\n",
    "    x_val = trn_df[trn_df.index.isin(val_idx)]\n",
    "    y_trn = trn_target[trn_target.index.isin(trn_idx)]\n",
    "    y_val = trn_target[trn_target.index.isin(val_idx)]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                               n_estimators=30000,\n",
    "                               learning_rate=0.1,\n",
    "                               colsample_bytree=0.2,\n",
    "                               objective='binary',\n",
    "                               n_jobs=-1)\n",
    "    \n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_metric='auc',\n",
    "              eval_set=[(x_val, y_val)],\n",
    "              verbose=100,\n",
    "              early_stopping_rounds=100)\n",
    "    \n",
    "    test_result += model.predict_proba(tst_df)[:, 1]\n",
    "    \n",
    "    del x_trn, x_val, y_trn, y_val\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result /= n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(DATA/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['HasDetections'] = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('lgb_5k_fold.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat 'lgb_5k_fold.csv' | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
